{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a42d86b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This notebook exemplifies how to calculate compound hazard metrics and plot their monthly patterns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae9174",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# Read all chosen indicators to represent hazards and plot seasonal patterns for single and compound events\n",
    "hwi= xr.open_dataset('heatwave_SMHI.nc')\n",
    "spei12_or= xr.open_dataset('SPEI12.nc')\n",
    "spei12 = spei12_or.resample(time='D').pad()\n",
    "# Perform linear interpolation to convert monthly data to daily data\n",
    "spei12 = spei12.interpolate_na(dim='time', method='linear')\n",
    "dfi= xr.open_dataset('Fidx.nc')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "804ddff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'time' dtype to datetime64[ns]\n",
    "dfi['time'] = xr.DataArray(pd.to_datetime(dfi.time.values))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# Load the data into memory\n",
    "dfi['flood_index'].load()\n",
    "# Convert the time variable to a Pandas datetime index\n",
    "dfi['time'] = pd.DatetimeIndex(dfi['time'].values)\n",
    "\n",
    "# Extract the flood_index variable as a DataArray\n",
    "dfi_flood_index = dfi['flood_index']\n",
    "\n",
    "start_date = pd.to_datetime('1922-01-31')\n",
    "end_date = pd.to_datetime('2021-12-31')\n",
    "\n",
    "# Truncate hwi array\n",
    "hwi = hwi.sel(time=slice(start_date, end_date))\n",
    "\n",
    "# Truncate spei12 array\n",
    "spei12= spei12.sel(time=slice(start_date, end_date))\n",
    "\n",
    "# Truncate dfi array\n",
    "dfi = dfi.sel(time=slice(start_date, end_date))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18b765d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming dfi is your DataFrame and flood_index is a column containing the data\n",
    "data = hwi['heatwave index'][:, 30, 30].values\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(data, bins='auto', color='blue', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Heatwave Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of HWI')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3c4ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming dfi is your DataFrame and flood_index is a column containing the data\n",
    "#data = spei12_or.SPEI[:, 30, 30].values # without interpolation\n",
    "data = spei12.SPEI[:, 30, 30].values # linearly interpolated\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(data, bins='auto', color='blue', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Drought Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of SPEI12')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcca6cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Assuming dfi is your DataFrame and flood_index is a column containing the data\n",
    "data = dfi.flood_index[:, 30, 30].values\n",
    "\n",
    "# Plotting the histogram\n",
    "plt.hist(data, bins='auto', color='blue', alpha=0.7)\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Flood Index')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Histogram of Flood Index')\n",
    "\n",
    "# Display the histogram\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00ac46a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad8e350",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def generate_bootstrapped_timeseries(spei12_series):\n",
    "    num_days = len(spei12_series)\n",
    "    #resampled_timeseries = np.empty((num_resamples, num_days))\n",
    "    # Generate random indices with replacement\n",
    "    random_indices = np.random.randint(0, num_days, size=num_days)\n",
    "    # Create the resampled timeseries using the random indices\n",
    "    resampled_timeseries = spei12_series[random_indices]\n",
    "    return resampled_timeseries\n",
    "# Calculate joint return period from joint probability of exceedance of two co-occuring hazards\n",
    "# Formulation from 'Global hotspots for the occurence of compound events'\n",
    "import numpy as np\n",
    "def rp(hwi_array, spei12_array, hwi_t, spei12_t, hwi_type, spei12_type):\n",
    "    rp_array = np.empty((hwi_array.shape[1], hwi_array.shape[2]))\n",
    "    rp_array[:] = np.nan\n",
    "    ns_array = rp_array.copy() # not statistically significant cells\n",
    "    with tqdm(total=hwi_array.shape[1]) as pbar:\n",
    "        for i in range(hwi_array.shape[1]):\n",
    "            #print(i)\n",
    "            for j in range(hwi_array.shape[2]):\n",
    "                if np.isnan(hwi_array[:, i, j]).any():\n",
    "                    continue\n",
    "                else:\n",
    "                    hwi_series = hwi_array[:, i, j].copy()\n",
    "                    spei12_series = spei12_array[:, i, j].copy()\n",
    "                    # 0: no event, 1: event happens\n",
    "                    if hwi_type == 'lower':\n",
    "                        hwi_series[hwi_series >= hwi_t] = 1\n",
    "                        hwi_series[hwi_series < hwi_t] = 0\n",
    "                    else:\n",
    "                        hwi_series[hwi_series > hwi_t] = 0\n",
    "                        hwi_series[hwi_series <= hwi_t] = 1\n",
    "                    if spei12_type == 'lower':\n",
    "                        spei12_series[spei12_series >= spei12_t] = 1\n",
    "                        spei12_series[spei12_series < spei12_t] = 0\n",
    "                    else:\n",
    "                        spei12_series[spei12_series > spei12_t] = 0\n",
    "                        spei12_series[spei12_series <= spei12_t] = 1\n",
    "                    # Create the joint_series by performing logical AND operation\n",
    "                    joint_series = np.array(hwi_series, dtype=int) & np.array(spei12_series, dtype=int)\n",
    "                    #print(joint_series)\n",
    "                    if np.nansum(joint_series)>0:\n",
    "                        # Calculate the daily probability of joint exceedance for a given month\n",
    "                        w = np.nansum(joint_series) # number of daily events in 100 years\n",
    "                        w_year= w/100 # average number of daily events in 1 year \n",
    "                        pjoint_exc = w_year / (365.25/12) # yearly probability of exceedance\n",
    "                        # Perform the significance test\n",
    "                        p = 0\n",
    "                        for N in range(1,1001):\n",
    "                            spei12_series_test = generate_bootstrapped_timeseries(spei12_series)\n",
    "                            joint_series_test = np.array(hwi_series, dtype=int) & np.array(spei12_series_test, dtype=int)\n",
    "                            ws = np.nansum(joint_series_test)\n",
    "                            n = np.random.uniform(-0.0009, 0.0009)\n",
    "                            ws_dis = ws + n\n",
    "                            if ws_dis>w: # check if disturbed sum is larger than original sum\n",
    "                                p = p+1\n",
    "                        #p = 10000 # skip test\n",
    "                        p_value= p/1000\n",
    "                        #rp_point = 1 / (pjoint_exc * (len(joint_series) / 100))\n",
    "                        rp_point = 1 / pjoint_exc\n",
    "                        rp_array[i, j] = rp_point\n",
    "                        # Check if it is significant\n",
    "                        if p_value < 0.05:  # 0.05 for 5% significance\n",
    "                            ns_array[i, j] = 1\n",
    "                            print('reject the null hypothesis that the joint exceedance between hazard X and hazard Y was introduced by random chance, not statistally significant at 5%')\n",
    "            pbar.update()\n",
    "    return rp_array, ns_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d7fd686",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48d6d563",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from cartopy.io import shapereader\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap\n",
    "def remove_leap_years(input_array, start_year):\n",
    "    years = np.arange(start_year, start_year + 100)\n",
    "    # Define the list of leap years\n",
    "    leap_years_list = [1924, 1928, 1932, 1936, 1940, 1944, 1948, 1952, 1956, 1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020]\n",
    "    # Find the indices corresponding to leap years in the years array\n",
    "    leap_year_indices = np.where(np.isin(years, leap_years_list))[0]\n",
    "    # Initialize the output array to store data without leap years\n",
    "    output_array = []\n",
    "    idx_start = 0\n",
    "    idx_end = 28\n",
    "    for i, year in enumerate(years):\n",
    "        # Skip data for leap years\n",
    "        output_array.append(input_array[idx_start:idx_end,:])\n",
    "        if i in leap_year_indices:\n",
    "            idx_start += 29\n",
    "            idx_end += 29\n",
    "        else:\n",
    "            idx_start += 28\n",
    "            idx_end += 28\n",
    "    # Convert the list of arrays to a single NumPy array with shape (2800, 100, 100)\n",
    "    output_array = np.concatenate(output_array, axis=0)\n",
    "    return output_array\n",
    "def rect_from_bound(xmin, xmax, ymin, ymax):\n",
    "    \"\"\"Returns list of (x,y)'s for a rectangle\"\"\"\n",
    "    xs = [xmax, xmin, xmin, xmax, xmax]\n",
    "    ys = [ymax, ymax, ymin, ymin, ymax]\n",
    "    return [(x, y) for x, y in zip(xs, ys)]\n",
    "\n",
    "def plot_rp(hazard, hwi, spei12, dfi):\n",
    "    sy= int(hwi.time.values[0].astype('M8[Y]').astype(str))\n",
    "    label = 'Joint return period (years): ' + hazard\n",
    "    # Define the custom colorbar intervals\n",
    "    custom_ticks = [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, 200, 300, 400, 500]\n",
    "    #[1, 1.5, 2, 5, 10, 15, 20, 30, 50, 75, 100]\n",
    "    #[1, 2, 5, 10, 25, 50, 75, 100, 200, 500]\n",
    "    # Set the boundaries for the colorbar intervals using BoundaryNorm\n",
    "    cmap = cm.jet_r\n",
    "    norm = mcolors.BoundaryNorm(custom_ticks, cmap.N, extend='both')\n",
    "    #cmap = cm.get_cmap(cmap, len(custom_ticks) - 1)\n",
    "    # Define a grayscale colormap\n",
    "    cmap_colors = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]  # Grey color for both values\n",
    "    gray_cmap = ListedColormap(cmap_colors, name='CustomGrey')\n",
    "    months = range(1, 13)\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    # Flatten the axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    # Loop over the axes and customize each subplot\n",
    "    with tqdm(total=len(months)) as pbar:\n",
    "        for i, ax in enumerate(axes):\n",
    "            month = months[i]\n",
    "            # Select data for the specific month\n",
    "            hwi_month = hwi.sel(time=hwi['time'].dt.month == month)\n",
    "            spei12_month = spei12.sel(time=spei12['time'].dt.month == month)\n",
    "            dfi_month = dfi_flood_index.where(dfi['time'].dt.month == month, drop=True)\n",
    "            hwi_array = hwi_month['heatwave index'].values\n",
    "            spei12_array = spei12_month['SPEI'].values\n",
    "            dfi_array = dfi_month.values\n",
    "            if i==0:\n",
    "                # Create a grid of longitudes and latitudes\n",
    "                lon_grid, lat_grid = np.meshgrid(hwi_month['lon'], hwi_month['lat'])\n",
    "                # Add the country boundaries\n",
    "                resolution = '10m'\n",
    "                category = 'cultural'\n",
    "                name = 'admin_0_countries'\n",
    "                shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "                df = gpd.read_file(shpfilename)\n",
    "                # get geometry of a country\n",
    "                poly = [df.loc[df['ADMIN'] == 'Sweden']['geometry'].values[0]]\n",
    "                stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "                pad1 = .1  # padding, degrees unit\n",
    "                exts = [poly[0].bounds[0] - pad1, poly[0].bounds[2] + pad1, poly[0].bounds[1] - pad1,\n",
    "                        poly[0].bounds[3] + pad1];\n",
    "                # make a mask polygon by polygon's difference operation\n",
    "                msk = Polygon(rect_from_bound(*exts)).difference(poly[0].simplify(0.01))\n",
    "                msk_stm = ccrs.PlateCarree().project_geometry(msk, ccrs.PlateCarree())  # project geometry to the projection used by stamen\n",
    "            ax.add_geometries(poly, crs=ccrs.PlateCarree(), facecolor='none', edgecolor='black')\n",
    "            ax.set_extent(exts, crs=ccrs.PlateCarree())\n",
    "            # plot the mask using semi-transparency (alpha=0.65) on the masked-out portion\n",
    "            ax.add_geometries(msk_stm, ccrs.PlateCarree(), zorder=12, facecolor='white', edgecolor='k', alpha=1)\n",
    "            # Plot the contour lines for the correlation between Hazards\n",
    "            if hazard[0:21] == 'heat wave and drought':\n",
    "                rp_array, ns_array=rp(hwi_array, spei12_array, 0, -1, 'lower', 'upper')\n",
    "                im = ax.imshow(rp_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, norm=norm)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:19] == 'heat wave and flood':\n",
    "                if month==2:\n",
    "                    hwi_array = remove_leap_years(hwi_array, sy)\n",
    "                rp_array, ns_array=rp(hwi_array, dfi_array, 0, 0, 'lower', 'lower')\n",
    "                im = ax.imshow(rp_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, norm=norm)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:17] == 'drought and flood':\n",
    "                if month==2:\n",
    "                    spei12_array = remove_leap_years(spei12_array, sy)\n",
    "                rp_array, ns_array=rp(dfi_array, spei12_array, 0, -1, 'lower', 'upper')\n",
    "                im = ax.imshow(rp_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, norm=norm)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard == 'heat wave' or hazard == 'drought' or hazard == 'flood':\n",
    "                label = 'Return period (years): ' + hazard\n",
    "                threshold_single=0\n",
    "                if hazard=='heat wave':\n",
    "                    haz_array=hwi_array\n",
    "                    haz_type='lower'\n",
    "                elif hazard=='drought':\n",
    "                    #spei12_month = spei12_or.sel(time=spei12_or['time'].dt.month == month)\n",
    "                    #spei12_array = spei12_month['SPEI'].values\n",
    "                    #custom_ticks = [0.0001, 0.001, 0.01, 0.1, 0.5, 1]\n",
    "                    #norm = mcolors.BoundaryNorm(custom_ticks, cmap.N, extend='both')\n",
    "                    haz_array=spei12_array\n",
    "                    haz_type='upper'\n",
    "                    threshold_single= -1\n",
    "                elif hazard=='flood':\n",
    "                    haz_array=dfi_array\n",
    "                    haz_type='lower'\n",
    "                rp_array, ns_array=rp_single(haz_array, threshold_single, haz_type)\n",
    "                im = ax.imshow(rp_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, norm=norm)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            # Add a title\n",
    "            month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September',\n",
    "                          'October', 'November', 'December']\n",
    "            ax.set_title(month_list[month - 1], fontsize=20)\n",
    "            pbar.update()\n",
    "    cbar_ax = fig.add_axes([0, 0, 1, 0.05])  # [left, bottom, width, height]\n",
    "    # Create the colorbar using the custom ticks and boundaries\n",
    "    # Create a custom colormap using ListedColormap\n",
    "    #colors = plt.cm.coolwarm_r(norm(np.arange(len(custom_ticks) - 1)))\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax, orientation='horizontal', extend='both',\n",
    "                        ticks=custom_ticks, boundaries=custom_ticks, norm=norm, cmap=cmap)\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    cbar.set_label(label, fontsize=20)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=-0.2)  # Adjust the value of hspace as needed to reduce the space between rows\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138ea734",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f57124",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('heat wave and drought', hwi, spei12, dfi, 'jet_r')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb0b575b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('heat wave and flood', hwi, spei12, dfi, 'jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12672933",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('drought and flood', hwi, spei12, dfi, 'jet_r') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4aadd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate joint return period from joint probability of exceedance of two co-occuring hazards\n",
    "# Formulation from 'Global hotspots for the occurence of compound events'\n",
    "import numpy as np\n",
    "def rp_single(hwi_array, hwi_t, hwi_type):\n",
    "    rp_array = np.empty((hwi_array.shape[1], hwi_array.shape[2]))\n",
    "    rp_array[:] = np.nan\n",
    "    ns_array = rp_array.copy() # not statistically significant cells\n",
    "    with tqdm(total=hwi_array.shape[1]) as pbar:\n",
    "        for i in range(hwi_array.shape[1]):\n",
    "            for j in range(hwi_array.shape[2]):\n",
    "                hwi_series = hwi_array[:, i, j].copy()\n",
    "                # 0: no event, 1: event happens\n",
    "                if hwi_type == 'lower':\n",
    "                    hwi_series[hwi_series >= hwi_t] = 1\n",
    "                    hwi_series[hwi_series < hwi_t] = 0\n",
    "                else:\n",
    "                    #print('upper type for droughts')\n",
    "                    hwi_series[hwi_series > hwi_t] = 0\n",
    "                    hwi_series[hwi_series <= hwi_t] = 1\n",
    "                \n",
    "                # Calculate the daily probability of joint exceedance for a given month\n",
    "                w = np.nansum(hwi_series)\n",
    "                w_year= w/100 # average number of daily events in 1 year \n",
    "                p_exc = w_year / (365.25/12) # yearly probability of exceedance\n",
    "                # Perform the significance test\n",
    "                p = 0\n",
    "                for N in range(1,1001):\n",
    "                    hwi_series_test = generate_bootstrapped_timeseries(hwi_series)\n",
    "                    ws = np.nansum(hwi_series_test)\n",
    "                    n = np.random.uniform(-0.0009, 0.0009)\n",
    "                    ws_dis = ws + n\n",
    "                    if ws_dis>w: # check if disturbed sum is larger than original sum\n",
    "                        p = p+1\n",
    "                p_value= p/1000\n",
    "                rp_point = 1 / p_exc # return period in years\n",
    "                rp_array[i, j] = rp_point\n",
    "                # Check if it is significant\n",
    "                if p_value < 0.05:  # 0.05 for 5% significance\n",
    "                    ns_array[i, j] = 1\n",
    "                    print('reject the null hypothesis that the joint exceedance between hazard X and hazard Y was introduced by random chance, not statistally significant at 5%')\n",
    "            pbar.update()\n",
    "    return rp_array, ns_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4eea979",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb8d11f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('heat wave', hwi, spei12, dfi, 'jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768572c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('drought', hwi, spei12, dfi, 'jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf71c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('flood', hwi, spei12, dfi, 'jet_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f71f44c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef7024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate Likelihood Multiplication Factor to check for independence and correlations\n",
    "# Formulation from 'Global hotspots for the occurence of compound events'\n",
    "import numpy as np\n",
    "def lmf(hwi_array, spei12_array, hwi_t, spei12_t, hwi_type, spei12_type):\n",
    "    lmf_array = np.empty((hwi_array.shape[1], hwi_array.shape[2]))\n",
    "    lmf_array[:] = np.nan\n",
    "    ns_array = lmf_array.copy() # not statistically significant cells\n",
    "    ns_array[:] = np.nan\n",
    "    with tqdm(total=hwi_array.shape[1]) as pbar:\n",
    "        for i in range(hwi_array.shape[1]):\n",
    "            #print(i)\n",
    "            for j in range(hwi_array.shape[2]):\n",
    "                if np.isnan(hwi_array[:, i, j]).any():\n",
    "                    continue\n",
    "                else:\n",
    "                    hwi_series = hwi_array[:, i, j].copy()\n",
    "                    spei12_series = spei12_array[:, i, j].copy()\n",
    "                    # 0: no event, 1: event happens\n",
    "                    if hwi_type == 'lower':\n",
    "                        hwi_series[hwi_series >= hwi_t] = 1\n",
    "                        hwi_series[hwi_series < hwi_t] = 0\n",
    "                    else:\n",
    "                        hwi_series[hwi_series > hwi_t] = 0\n",
    "                        hwi_series[hwi_series <= hwi_t] = 1\n",
    "                    if spei12_type == 'lower':\n",
    "                        spei12_series[spei12_series >= spei12_t] = 1\n",
    "                        spei12_series[spei12_series < spei12_t] = 0\n",
    "                    else:\n",
    "                        spei12_series[spei12_series > spei12_t] = 0\n",
    "                        spei12_series[spei12_series <= spei12_t] = 1\n",
    "                    # Create the joint_series by performing logical AND operation\n",
    "                    joint_series = np.array(hwi_series, dtype=int) & np.array(spei12_series, dtype=int)\n",
    "                    if np.nansum(joint_series)>0:\n",
    "                        # Calculate the daily probability of joint exceedance for a given month\n",
    "                        w = np.nansum(joint_series)\n",
    "                        pactual = w / len(joint_series)\n",
    "                        # Perform the significance test\n",
    "                        p = 0\n",
    "                        for N in range(1,1001):\n",
    "                            spei12_series_test = generate_bootstrapped_timeseries(spei12_series)\n",
    "                            joint_series_test = np.array(hwi_series, dtype=int) & np.array(spei12_series_test, dtype=int)\n",
    "                            ws = np.nansum(joint_series_test)\n",
    "                            n = np.random.uniform(-0.0009, 0.0009)\n",
    "                            ws_dis = ws + n\n",
    "                            if ws_dis>w: # check if disturbed sum is larger than original sum\n",
    "                                p = p+1\n",
    "                        p_value= p/1000\n",
    "                        #p_value=1\n",
    "                        # Calculate pindep\n",
    "                        pindep = np.nansum(hwi_series) / len(hwi_series) * np.nansum(spei12_series) / len(spei12_series)\n",
    "                        #print(pindep)\n",
    "                        #print(pactual)\n",
    "                        lmf_point = pactual / pindep\n",
    "                        lmf_array[i, j] = lmf_point\n",
    "                        # Check if it is significant\n",
    "                        if p_value < 0.05:  # 0.05 for 5% significance\n",
    "                            ns_array[i, j] = 1\n",
    "                            print('reject the null hypothesis that the joint exceedance between hazard X and hazard Y was introduced by random chance, not statistally significant at 5%')\n",
    "            pbar.update()\n",
    "    return lmf_array, ns_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75691fe5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6bf142",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from cartopy.io import shapereader\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap \n",
    "def remove_leap_years(input_array, start_year):\n",
    "    years = np.arange(start_year, start_year + 100)\n",
    "    # Define the list of leap years\n",
    "    leap_years_list = [1924, 1928, 1932, 1936, 1940, 1944, 1948, 1952, 1956, 1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020]\n",
    "    # Find the indices corresponding to leap years in the years array\n",
    "    leap_year_indices = np.where(np.isin(years, leap_years_list))[0]\n",
    "    # Initialize the output array to store data without leap years\n",
    "    output_array = []\n",
    "    idx_start = 0\n",
    "    idx_end = 28\n",
    "    for i, year in enumerate(years):\n",
    "        # Skip data for leap years\n",
    "        output_array.append(input_array[idx_start:idx_end,:])\n",
    "        if i in leap_year_indices:\n",
    "            idx_start += 29\n",
    "            idx_end += 29\n",
    "        else:\n",
    "            idx_start += 28\n",
    "            idx_end += 28\n",
    "    # Convert the list of arrays to a single NumPy array with shape (2800, 100, 100)\n",
    "    output_array = np.concatenate(output_array, axis=0)\n",
    "    return output_array\n",
    "def rect_from_bound(xmin, xmax, ymin, ymax):\n",
    "    \"\"\"Returns list of (x,y)'s for a rectangle\"\"\"\n",
    "    xs = [xmax, xmin, xmin, xmax, xmax]\n",
    "    ys = [ymax, ymax, ymin, ymin, ymax]\n",
    "    return [(x, y) for x, y in zip(xs, ys)]\n",
    "class MidpointNormalize(mcolors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mcolors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        v_ext = np.max( [ np.abs(self.vmin), np.abs(self.vmax) ] )\n",
    "        x, y = [-v_ext, self.midpoint, v_ext], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_lmf(hazard, hwi, spei12, dfi):\n",
    "    sy=int(hwi.time.values[0].astype('M8[Y]').astype(str))\n",
    "    # Define the custom colorbar intervals\n",
    "    custom_ticks = [0, 1, 2]\n",
    "    # Create a custom color map\n",
    "    minimum=0\n",
    "    maximum=2\n",
    "    midpoint = 1\n",
    "    val = midpoint / maximum\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"mycolormap\",\n",
    "        colors=[\n",
    "        (0.0, [0.0, 0.0, 0.5]),  # Dark blue\n",
    "        (0.25, [0.6, 0.8, 1.0]),  # Light blue\n",
    "        (0.45, [0.7, 1.0, 0.7]),  # Light green\n",
    "        (0.50, [0.0, 0.5, 0.0]),  # Green\n",
    "        (0.55, [1.0, 0.7, 0.7]),  # Light red\n",
    "        (0.80, [1.0, 0.0, 0.0]),  # Red\n",
    "        (1.0, [0.5, 0.0, 0.0])  # Dark red\n",
    "            ]\n",
    "    )\n",
    "    #norm = mcolors.BoundaryNorm(custom_ticks, len(custom_ticks) - 1)\n",
    "    # Define a grayscale colormap\n",
    "    cmap_colors = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]  # Grey color for not significant values\n",
    "    gray_cmap = ListedColormap(cmap_colors, name='CustomGrey')\n",
    "    months = range(1, 13)\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    # Flatten the axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    # Loop over the axes and customize each subplot\n",
    "    with tqdm(total=len(months)) as pbar:\n",
    "        for i, ax in enumerate(axes):\n",
    "            month = months[i]\n",
    "            # Select data for the specific month\n",
    "            hwi_month = hwi.sel(time=hwi['time'].dt.month == month)\n",
    "            spei12_month = spei12.sel(time=spei12['time'].dt.month == month)\n",
    "            dfi_month = dfi_flood_index.where(dfi['time'].dt.month == month, drop=True)\n",
    "            hwi_array = hwi_month['heatwave index'].values\n",
    "            spei12_array = spei12_month['SPEI'].values\n",
    "            dfi_array = dfi_month.values\n",
    "            if i==0:\n",
    "                # Create a grid of longitudes and latitudes\n",
    "                lon_grid, lat_grid = np.meshgrid(hwi_month['lon'], hwi_month['lat'])\n",
    "                # Add the country boundaries\n",
    "                resolution = '10m'\n",
    "                category = 'cultural'\n",
    "                name = 'admin_0_countries'\n",
    "                shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "                df = gpd.read_file(shpfilename)\n",
    "                # get geometry of a country\n",
    "                poly = [df.loc[df['ADMIN'] == 'Sweden']['geometry'].values[0]]\n",
    "                stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "                pad1 = .1  # padding, degrees unit\n",
    "                exts = [poly[0].bounds[0] - pad1, poly[0].bounds[2] + pad1, poly[0].bounds[1] - pad1,\n",
    "                        poly[0].bounds[3] + pad1];\n",
    "                # make a mask polygon by polygon's difference operation\n",
    "                msk = Polygon(rect_from_bound(*exts)).difference(poly[0].simplify(0.01))\n",
    "                msk_stm = ccrs.PlateCarree().project_geometry(msk, ccrs.PlateCarree())  # project geometry to the projection used by stamen\n",
    "            ax.add_geometries(poly, crs=ccrs.PlateCarree(), facecolor='none', edgecolor='black')\n",
    "            ax.set_extent(exts, crs=ccrs.PlateCarree())\n",
    "            # plot the mask using semi-transparency (alpha=0.65) on the masked-out portion\n",
    "            ax.add_geometries(msk_stm, ccrs.PlateCarree(), zorder=12, facecolor='white', edgecolor='k', alpha=1)\n",
    "            # Plot the contour lines for the correlation between Hazards\n",
    "            if hazard[0:21] == 'heat wave and drought':\n",
    "                lmf_array, ns_array=lmf(hwi_array, spei12_array, 0, -1, 'lower', 'upper')\n",
    "                #print(np.nanmin(lmf_array), np.nanmax(lmf_array))\n",
    "                im = ax.imshow(lmf_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=0, vmax=2)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:19] == 'heat wave and flood':\n",
    "                if month==2:\n",
    "                    hwi_array = remove_leap_years(hwi_array, sy)\n",
    "                lmf_array, ns_array=lmf(hwi_array, dfi_array, 0, 0, 'lower', 'lower')\n",
    "                im = ax.imshow(lmf_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=0, vmax=2)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:17] == 'drought and flood':\n",
    "                if month==2:\n",
    "                    spei12_array = remove_leap_years(spei12_array, sy)\n",
    "                lmf_array, ns_array=lmf(dfi_array, spei12_array, 0, -1, 'lower', 'upper')\n",
    "                im = ax.imshow(lmf_array,\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=0, vmax=2)\n",
    "                im2 = ax.imshow(ns_array,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            # Add a title\n",
    "            month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September',\n",
    "                          'October', 'November', 'December']\n",
    "            ax.set_title(month_list[month - 1], fontsize=20)\n",
    "            pbar.update()\n",
    "    cbar_ax = fig.add_axes([0, 0, 1, 0.05])  # [left, bottom, width, height]\n",
    "    # Create the colorbar using the custom ticks and boundaries\n",
    "    # Create a custom colormap using ListedColormap\n",
    "    #colors = plt.cm.coolwarm_r(norm(np.arange(len(custom_ticks) - 1)))\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax, ticks=custom_ticks, cmap=cmap, \n",
    "                        orientation='horizontal', extend='max')\n",
    "    #cbar.set_ticklabels(['0', '1', '10'])  # Set tick labels\n",
    "    #cbar.set_ticks(custom_ticks)  # Set tick positions\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    label = 'Likelihood multiplication factor: ' + hazard\n",
    "    cbar.set_label(label, fontsize=20)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=-0.2)  # Adjust the value of hspace as needed to reduce the space between rows\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8020e69f",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf('heat wave and drought', hwi, spei12, dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9af989d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf('heat wave and flood', hwi, spei12, dfi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec31b6fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf('drought and flood', hwi, spei12, dfi) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070369d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from cartopy.io import shapereader\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap \n",
    "def lmf_change(lmf_array_1, lmf_array_2):\n",
    "    # Assuming lmf_array_1 and lmf_array_2 have the same shape\n",
    "    # Calculate the relative change as a percentage\n",
    "    lmf_array_change = ((lmf_array_2 - lmf_array_1) / lmf_array_1) * 100\n",
    "    # If you want to handle cases where the denominator (lmf_array_1) is zero (NaN after replacement),\n",
    "    # you can set those elements in lmf_array_change to NaN\n",
    "    lmf_array_change[np.isnan(lmf_array_1)] = np.nan\n",
    "    return lmf_array_change\n",
    "def remove_leap_years(input_array, start_year):\n",
    "    years = np.arange(start_year, start_year + 100)\n",
    "    # Define the list of leap years\n",
    "    leap_years_list = [1924, 1928, 1932, 1936, 1940, 1944, 1948, 1952, 1956, 1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020]\n",
    "    # Find the indices corresponding to leap years in the years array\n",
    "    leap_year_indices = np.where(np.isin(years, leap_years_list))[0]\n",
    "    # Initialize the output array to store data without leap years\n",
    "    output_array = []\n",
    "    idx_start = 0\n",
    "    idx_end = 28\n",
    "    for i, year in enumerate(years):\n",
    "        # Skip data for leap years\n",
    "        output_array.append(input_array[idx_start:idx_end,:])\n",
    "        if i in leap_year_indices:\n",
    "            idx_start += 29\n",
    "            idx_end += 29\n",
    "        else:\n",
    "            idx_start += 28\n",
    "            idx_end += 28\n",
    "    # Convert the list of arrays to a single NumPy array with shape (2800, 100, 100)\n",
    "    output_array = np.concatenate(output_array, axis=0)\n",
    "    return output_array\n",
    "def rect_from_bound(xmin, xmax, ymin, ymax):\n",
    "    \"\"\"Returns list of (x,y)'s for a rectangle\"\"\"\n",
    "    xs = [xmax, xmin, xmin, xmax, xmax]\n",
    "    ys = [ymax, ymax, ymin, ymin, ymax]\n",
    "    return [(x, y) for x, y in zip(xs, ys)]\n",
    "class MidpointNormalize(mcolors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mcolors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        v_ext = np.max( [ np.abs(self.vmin), np.abs(self.vmax) ] )\n",
    "        x, y = [-v_ext, self.midpoint, v_ext], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_lmf_diff(hazard, hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2):\n",
    "    # Define the custom colorbar intervals\n",
    "    custom_ticks = [-100, -80, -60, -40, -20, 0, 20, 40, 60, 80, 100]\n",
    "    # Create a custom color map\n",
    "    minimum=-100\n",
    "    maximum=100\n",
    "    midpoint = 0\n",
    "    cmap = 'coolwarm'\n",
    "    # Define a grayscale colormap\n",
    "    cmap_colors = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]  # Grey color for not significant values\n",
    "    gray_cmap = ListedColormap(cmap_colors, name='CustomGrey')\n",
    "    months = range(1, 13)\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    # Flatten the axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    # Loop over the axes and customize each subplot\n",
    "    with tqdm(total=len(months)) as pbar:\n",
    "        for i, ax in enumerate(axes):\n",
    "            month = months[i]\n",
    "            # Select data for the specific month\n",
    "            hwi_month_1 = hwi_1.sel(time=hwi_1['time'].dt.month == month)\n",
    "            spei12_month_1 = spei12_1.sel(time=spei12_1['time'].dt.month == month)\n",
    "            dfi_flood_index = dfi_1['flood_index']\n",
    "            dfi_month_1 = dfi_flood_index.where(dfi_1['time'].dt.month == month, drop=True)\n",
    "            hwi_array_1 = hwi_month_1['heatwave index'].values\n",
    "            spei12_array_1 = spei12_month_1['SPEI'].values\n",
    "            dfi_array_1 = dfi_month_1.values\n",
    "            \n",
    "            hwi_month_2 = hwi_2.sel(time=hwi_2['time'].dt.month == month)\n",
    "            spei12_month_2 = spei12_2.sel(time=spei12_2['time'].dt.month == month)\n",
    "            dfi_flood_index = dfi_2['flood_index']\n",
    "            dfi_month_2 = dfi_flood_index.where(dfi_2['time'].dt.month == month, drop=True)\n",
    "            hwi_array_2 = hwi_month_2['heatwave index'].values\n",
    "            spei12_array_2 = spei12_month_2['SPEI'].values\n",
    "            dfi_array_2 = dfi_month_2.values\n",
    "            if i==0:\n",
    "                # Create a grid of longitudes and latitudes\n",
    "                lon_grid, lat_grid = np.meshgrid(hwi_month_1['lon'], hwi_month_1['lat'])\n",
    "                # Add the country boundaries\n",
    "                resolution = '10m'\n",
    "                category = 'cultural'\n",
    "                name = 'admin_0_countries'\n",
    "                shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "                df = gpd.read_file(shpfilename)\n",
    "                # get geometry of a country\n",
    "                poly = [df.loc[df['ADMIN'] == 'Sweden']['geometry'].values[0]]\n",
    "                stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "                pad1 = .1  # padding, degrees unit\n",
    "                exts = [poly[0].bounds[0] - pad1, poly[0].bounds[2] + pad1, poly[0].bounds[1] - pad1,\n",
    "                        poly[0].bounds[3] + pad1];\n",
    "                # make a mask polygon by polygon's difference operation\n",
    "                msk = Polygon(rect_from_bound(*exts)).difference(poly[0].simplify(0.01))\n",
    "                msk_stm = ccrs.PlateCarree().project_geometry(msk, ccrs.PlateCarree())  # project geometry to the projection used by stamen\n",
    "            ax.add_geometries(poly, crs=ccrs.PlateCarree(), facecolor='none', edgecolor='black')\n",
    "            ax.set_extent(exts, crs=ccrs.PlateCarree())\n",
    "            # plot the mask using semi-transparency (alpha=0.65) on the masked-out portion\n",
    "            ax.add_geometries(msk_stm, ccrs.PlateCarree(), zorder=12, facecolor='white', edgecolor='k', alpha=1)\n",
    "            # Plot the contour lines for the correlation between Hazards\n",
    "            if hazard[0:21] == 'heat wave and drought':\n",
    "                lmf_array_1, ns_array_1=lmf(hwi_array_1, spei12_array_1, 0, -1, 'lower', 'upper')\n",
    "                lmf_array_2, ns_array_2=lmf(hwi_array_2, spei12_array_2, 0, -1, 'lower', 'upper')\n",
    "                #print(np.nanmin(lmf_array), np.nanmax(lmf_array))\n",
    "                im = ax.imshow(lmf_change(lmf_array_1, lmf_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:19] == 'heat wave and flood':\n",
    "                if month==2:\n",
    "                    hwi_array_1 = remove_leap_years(hwi_array_1, 1922)\n",
    "                    hwi_array_2 = remove_leap_years(hwi_array_2, 1972)\n",
    "                lmf_array_1, ns_array_1=lmf(hwi_array_1, dfi_array_1, 0, 0, 'lower', 'lower')\n",
    "                lmf_array_2, ns_array_2=lmf(hwi_array_2, dfi_array_2, 0, 0, 'lower', 'lower')\n",
    "                im = ax.imshow(lmf_change(lmf_array_1, lmf_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:17] == 'drought and flood':\n",
    "                if month==2:\n",
    "                    spei12_array_1 = remove_leap_years(spei12_array_1, 1922)\n",
    "                    spei12_array_2 = remove_leap_years(spei12_array_2, 1972)\n",
    "                lmf_array_1, ns_array_1=lmf(dfi_array_1, spei12_array_1, 0, -1, 'lower', 'upper')\n",
    "                lmf_array_2, ns_array_2=lmf(dfi_array_2, spei12_array_2, 0, -1, 'lower', 'upper')\n",
    "                im = ax.imshow(lmf_change(lmf_array_1, lmf_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            # Add a title\n",
    "            month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September',\n",
    "                          'October', 'November', 'December']\n",
    "            ax.set_title(month_list[month - 1], fontsize=20)\n",
    "            pbar.update()\n",
    "    cbar_ax = fig.add_axes([0, 0, 1, 0.05])  # [left, bottom, width, height]\n",
    "    # Create the colorbar using the custom ticks and boundaries\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax, ticks=custom_ticks, cmap=cmap, \n",
    "                        orientation='horizontal', extend='both')\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    label = 'Relative Change of LMF Between 1972-2021 and 1922-1971 (%): ' + hazard\n",
    "    cbar.set_label(label, fontsize=20)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=-0.2)  # Adjust the value of hspace as needed to reduce the space between rows\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d650caf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate change of return periods from 1922-1971 and 1972-2021\n",
    "start_date1 = pd.to_datetime('1922-01-31')\n",
    "end_date1 = pd.to_datetime('1971-12-31')\n",
    "\n",
    "# Truncate hwi array\n",
    "hwi_1 = hwi.sel(time=slice(start_date1, end_date1))\n",
    "\n",
    "# Truncate spei12 array\n",
    "spei12_1 = spei12.sel(time=slice(start_date1, end_date1))\n",
    "\n",
    "# Truncate dfi array\n",
    "dfi_1 = dfi.sel(time=slice(start_date1, end_date1))\n",
    "\n",
    "start_date2 = pd.to_datetime('1972-01-01')\n",
    "end_date2 = pd.to_datetime('2021-12-31')\n",
    "\n",
    "# Truncate hwi array\n",
    "hwi_2 = hwi.sel(time=slice(start_date2, end_date2))\n",
    "\n",
    "# Truncate spei12 array\n",
    "spei12_2 = spei12.sel(time=slice(start_date2, end_date2))\n",
    "\n",
    "# Truncate dfi array\n",
    "dfi_2 = dfi.sel(time=slice(start_date2, end_date2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49147085",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d56a8833",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_lmf('heat wave and drought (1922-1971)', hwi_1, spei12_1, dfi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02c439ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf('heat wave and drought (1972-2021)', hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f504b1c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de114382",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf_diff('heat wave and drought', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c89851",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf_diff('drought and flood', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb79dae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_lmf_diff('heat wave and flood', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7555b21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c7320e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e581a22a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2cec6ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from shapely.geometry import Polygon\n",
    "from cartopy.io import shapereader\n",
    "import cartopy.io.img_tiles as cimgt\n",
    "import cartopy.crs as ccrs\n",
    "import geopandas as gpd\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.colors as mcolors\n",
    "import matplotlib.cm as cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap \n",
    "def rp_change(rp_array_1, rp_array_2):\n",
    "    # Calculate the absolute change \n",
    "    rp_array_change = (rp_array_2 - rp_array_1)\n",
    "    return rp_array_change\n",
    "def remove_leap_years(input_array, start_year):\n",
    "    years = np.arange(start_year, start_year + 100)\n",
    "    # Define the list of leap years\n",
    "    leap_years_list = [1924, 1928, 1932, 1936, 1940, 1944, 1948, 1952, 1956, 1960, 1964, 1968, 1972, 1976, 1980, 1984, 1988, 1992, 1996, 2000, 2004, 2008, 2012, 2016, 2020]\n",
    "    # Find the indices corresponding to leap years in the years array\n",
    "    leap_year_indices = np.where(np.isin(years, leap_years_list))[0]\n",
    "    # Initialize the output array to store data without leap years\n",
    "    output_array = []\n",
    "    idx_start = 0\n",
    "    idx_end = 28\n",
    "    for i, year in enumerate(years):\n",
    "        # Skip data for leap years\n",
    "        output_array.append(input_array[idx_start:idx_end,:])\n",
    "        if i in leap_year_indices:\n",
    "            idx_start += 29\n",
    "            idx_end += 29\n",
    "        else:\n",
    "            idx_start += 28\n",
    "            idx_end += 28\n",
    "    # Convert the list of arrays to a single NumPy array with shape (2800, 100, 100)\n",
    "    output_array = np.concatenate(output_array, axis=0)\n",
    "    return output_array\n",
    "def rect_from_bound(xmin, xmax, ymin, ymax):\n",
    "    \"\"\"Returns list of (x,y)'s for a rectangle\"\"\"\n",
    "    xs = [xmax, xmin, xmin, xmax, xmax]\n",
    "    ys = [ymax, ymax, ymin, ymin, ymax]\n",
    "    return [(x, y) for x, y in zip(xs, ys)]\n",
    "class MidpointNormalize(mcolors.Normalize):\n",
    "    def __init__(self, vmin=None, vmax=None, midpoint=None, clip=False):\n",
    "        self.midpoint = midpoint\n",
    "        mcolors.Normalize.__init__(self, vmin, vmax, clip)\n",
    "\n",
    "    def __call__(self, value, clip=None):\n",
    "        v_ext = np.max( [ np.abs(self.vmin), np.abs(self.vmax) ] )\n",
    "        x, y = [-v_ext, self.midpoint, v_ext], [0, 0.5, 1]\n",
    "        return np.ma.masked_array(np.interp(value, x, y))\n",
    "\n",
    "def plot_rp_diff(hazard, hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2):\n",
    "    # Define the custom colorbar intervals\n",
    "    custom_ticks = [-100, -80, -60, -40, -20, 0, 20, 40, 60, 80, 100]\n",
    "    minimum=-100\n",
    "    maximum=100\n",
    "    midpoint = 0\n",
    "    cmap = 'coolwarm_r'\n",
    "    #norm = mcolors.BoundaryNorm(custom_ticks, len(custom_ticks) - 1)\n",
    "    # Define a grayscale colormap\n",
    "    cmap_colors = [(0.5, 0.5, 0.5), (0.5, 0.5, 0.5)]  # Grey color for not significant values\n",
    "    gray_cmap = ListedColormap(cmap_colors, name='CustomGrey')\n",
    "    months = range(1, 13)\n",
    "    # Set up the figure and axes\n",
    "    fig, axes = plt.subplots(nrows=2, ncols=6, figsize=(16, 8), subplot_kw={'projection': ccrs.PlateCarree()})\n",
    "    # Flatten the axes array for easier iteration\n",
    "    axes = axes.flatten()\n",
    "    # Loop over the axes and customize each subplot\n",
    "    with tqdm(total=len(months)) as pbar:\n",
    "        for i, ax in enumerate(axes):\n",
    "            month = months[i]\n",
    "            # Select data for the specific month\n",
    "            hwi_month_1 = hwi_1.sel(time=hwi_1['time'].dt.month == month)\n",
    "            spei12_month_1 = spei12_1.sel(time=spei12_1['time'].dt.month == month)\n",
    "            dfi_flood_index = dfi_1['flood_index']\n",
    "            dfi_month_1 = dfi_flood_index.where(dfi_1['time'].dt.month == month, drop=True)\n",
    "            hwi_array_1 = hwi_month_1['heatwave index'].values\n",
    "            spei12_array_1 = spei12_month_1['SPEI'].values\n",
    "            dfi_array_1 = dfi_month_1.values\n",
    "            \n",
    "            hwi_month_2 = hwi_2.sel(time=hwi_2['time'].dt.month == month)\n",
    "            spei12_month_2 = spei12_2.sel(time=spei12_2['time'].dt.month == month)\n",
    "            dfi_flood_index = dfi_2['flood_index']\n",
    "            dfi_month_2 = dfi_flood_index.where(dfi_2['time'].dt.month == month, drop=True)\n",
    "            hwi_array_2 = hwi_month_2['heatwave index'].values\n",
    "            spei12_array_2 = spei12_month_2['SPEI'].values\n",
    "            dfi_array_2 = dfi_month_2.values\n",
    "            if i==0:\n",
    "                # Create a grid of longitudes and latitudes\n",
    "                lon_grid, lat_grid = np.meshgrid(hwi_month_1['lon'], hwi_month_1['lat'])\n",
    "                # Add the country boundaries\n",
    "                resolution = '10m'\n",
    "                category = 'cultural'\n",
    "                name = 'admin_0_countries'\n",
    "                shpfilename = shapereader.natural_earth(resolution, category, name)\n",
    "                df = gpd.read_file(shpfilename)\n",
    "                # get geometry of a country\n",
    "                poly = [df.loc[df['ADMIN'] == 'Sweden']['geometry'].values[0]]\n",
    "                stamen_terrain = cimgt.Stamen('terrain-background')\n",
    "                pad1 = .1  # padding, degrees unit\n",
    "                exts = [poly[0].bounds[0] - pad1, poly[0].bounds[2] + pad1, poly[0].bounds[1] - pad1,\n",
    "                        poly[0].bounds[3] + pad1];\n",
    "                # make a mask polygon by polygon's difference operation\n",
    "                msk = Polygon(rect_from_bound(*exts)).difference(poly[0].simplify(0.01))\n",
    "                msk_stm = ccrs.PlateCarree().project_geometry(msk, ccrs.PlateCarree())  # project geometry to the projection used by stamen\n",
    "            ax.add_geometries(poly, crs=ccrs.PlateCarree(), facecolor='none', edgecolor='black')\n",
    "            ax.set_extent(exts, crs=ccrs.PlateCarree())\n",
    "            # plot the mask using semi-transparency (alpha=0.65) on the masked-out portion\n",
    "            ax.add_geometries(msk_stm, ccrs.PlateCarree(), zorder=12, facecolor='white', edgecolor='k', alpha=1)\n",
    "            # Plot the contour lines for the correlation between Hazards\n",
    "            if hazard[0:21] == 'heat wave and drought':\n",
    "                rp_array_1, ns_array_1=rp(hwi_array_1, spei12_array_1, 0, -1, 'lower', 'upper')\n",
    "                rp_array_2, ns_array_2=rp(hwi_array_2, spei12_array_2, 0, -1, 'lower', 'upper')\n",
    "                #print(np.nanmin(rp_array), np.nanmax(rp_array))\n",
    "                im = ax.imshow(rp_change(rp_array_1, rp_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:19] == 'heat wave and flood':\n",
    "                if month==2:\n",
    "                    hwi_array_1 = remove_leap_years(hwi_array_1, 1922)\n",
    "                    hwi_array_2 = remove_leap_years(hwi_array_2, 1972)\n",
    "                rp_array_1, ns_array_1=rp(hwi_array_1, dfi_array_1, 0, 0, 'lower', 'lower')\n",
    "                rp_array_2, ns_array_2=rp(hwi_array_2, dfi_array_2, 0, 0, 'lower', 'lower')\n",
    "                im = ax.imshow(rp_change(rp_array_1, rp_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            elif hazard[0:17] == 'drought and flood':\n",
    "                if month==2:\n",
    "                    spei12_array_1 = remove_leap_years(spei12_array_1, 1922)\n",
    "                    spei12_array_2 = remove_leap_years(spei12_array_2, 1972)\n",
    "                rp_array_1, ns_array_1=rp(dfi_array_1, spei12_array_1, 0, -1, 'lower', 'upper')\n",
    "                rp_array_2, ns_array_2=rp(dfi_array_2, spei12_array_2, 0, -1, 'lower', 'upper')\n",
    "                im = ax.imshow(rp_change(rp_array_1, rp_array_2),\n",
    "                            origin='lower',\n",
    "                            extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                            cmap=cmap, zorder=11, vmin=-100, vmax=100)\n",
    "                im2 = ax.imshow(ns_array_1,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "                im3 = ax.imshow(ns_array_2,\n",
    "                           origin='lower',\n",
    "                           extent=[lon_grid.min(), lon_grid.max(), lat_grid.min(), lat_grid.max()],\n",
    "                           cmap=gray_cmap, zorder=11)\n",
    "            # Add a title\n",
    "            month_list = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September',\n",
    "                          'October', 'November', 'December']\n",
    "            ax.set_title(month_list[month - 1], fontsize=20)\n",
    "            pbar.update()\n",
    "    cbar_ax = fig.add_axes([0, 0, 1, 0.05])  # [left, bottom, width, height]\n",
    "    # Create the colorbar using the custom ticks and boundaries\n",
    "    # Create a custom colormap using ListedColormap\n",
    "    #colors = plt.cm.coolwarm_r(norm(np.arange(len(custom_ticks) - 1)))\n",
    "    cbar = plt.colorbar(im, cax=cbar_ax, ticks=custom_ticks, cmap=cmap, \n",
    "                        orientation='horizontal', extend='both')\n",
    "    #cbar.set_ticklabels(['0', '1', '10'])  # Set tick labels\n",
    "    #cbar.set_ticks(custom_ticks)  # Set tick positions\n",
    "    cbar.ax.tick_params(labelsize=20)\n",
    "    label = 'Change of Return Periods Between 1972-2021 and 1922-1971 (years): ' + hazard\n",
    "    cbar.set_label(label, fontsize=20)\n",
    "    plt.subplots_adjust(wspace=0.2, hspace=-0.2)  # Adjust the value of hspace as needed to reduce the space between rows\n",
    "    plt.tight_layout()\n",
    "    # Show the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc9fbf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('heat wave and drought (1922-1971)', hwi_1, spei12_1, dfi_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97eb0216",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp('heat wave and drought (1972-2021)', hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3996c9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada7bd1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp_diff('heat wave and drought', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b0e3b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp_diff('drought and flood', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76afdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_rp_diff('heat wave and flood', hwi_1, spei12_1, dfi_1, hwi_2, spei12_2, dfi_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f97f041",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
